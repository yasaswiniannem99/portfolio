<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Document</title>
    <!--style.css-->
	<link rel="stylesheet" href="assets/css/style.css">
</head>
<body>
    <h1 class="project-details-heading">Responsibilities</h1>
    <ol class="olcards">
		<li style="--cardColor:#940B92">
			<div class="content">
				<div class="text">Experience in fact dimensional modeling (Star schema, Snowflake schema), transactional modeling and SCD (Slowly changing dimension).</div>
			</div>
		</li>
		<li style="--cardColor:#363062">
			<div class="content">
				<div class="text">Implemented Apache Airflow for authoring, scheduling and monitoring Data Pipelines.</div>
			</div>
		</li>
		<li style="--cardColor:#005B41">
			<div class="content">
				<div class="text">Extract Transform and Load data from Sources Systems to Azure Data Storage services using a combination of Azure Data Factory, T-SQL, Spark SQL and Azure Data Lake Analytics. Data Ingestion to one or more Azure Services - (Azure Data Lake, Azure Storage, Azure SQL, Azure DW) and processing the data in In Azure Databricks.</div>
			</div>
		</li>
		<li style="--cardColor:#008170">
			<div class="content">
				<div class="text">Developed and implemented ETL pipelines using Python, SQL, Spark and PySpark to ingest data and updates to relevant databases.</div>
			</div>
		</li>
        <li style="--cardColor:#04364A">
			<div class="content">
				<div class="text">Extensively worked with pyspark / Spark SQL for data cleansing and generating Data Frames and RDDs.</div>
			</div>
		</li>
        <li style="--cardColor:#64CCC5">
			<div class="content">
				<div class="text">Created Pipelines in ADF using Linked Services/Datasets/Pipeline/ to Extract, Transform, and load data from different sources like Azure SQL, Blob storage, Azure SQL Data warehouse, write-back tool and backwards.</div>
			</div>
		</li>
        <li style="--cardColor:#186F65">
			<div class="content">
				<div class="text">Designed and developed Informatica workflows to exchange data with Oracle databases, Salesforce, Data Lake, and other operational and warehouse data stores, ensuring seamless data integration.</div>
			</div>
		</li>
        <li style="--cardColor:#183D3D">
			<div class="content">
				<div class="text">Collaborated with infrastructure teams to optimize Informatica objects, enhance throughput, and plan for capacity, resulting in improved system performance.</div>
			</div>
		</li>
        <li style="--cardColor:#79155B">
			<div class="content">
				<div class="text">Configured and tuned complex Informatica maps, workflows, and session logs, meeting performance and recovery objectives.</div>
			</div>
		</li>
        <li style="--cardColor:#461959">
			<div class="content">
				<div class="text">Designed, Created, Executed, Review of Unit Test case , SIT(System Integration Testing) Test Cases , Functional Test Cases based on Client Requirements.</div>
			</div>
		</li>
        <li style="--cardColor:#898121">
			<div class="content">
				<div class="text">Created Spark code to process streaming data from Kafka cluster and load the data to staging area for processing.</div>
			</div>
		</li>
        <li style="--cardColor:#AF2655">
			<div class="content">
				<div class="text">Involved in Functional Testing, Integration testing, Regression Testing, Smoke testing and performance Testing. Tested Hadoop Map Reduce developed in python, pig, Hive.</div>
			</div>
		</li>
        <li style="--cardColor:#BE3144">
			<div class="content">
				<div class="text">Implemented CI/CD pipelines using Git and Jenkins for efficient code integration and deployment.</div>
			</div>
		</li>
        <li style="--cardColor:#164863">
			<div class="content">
				<div class="text">Involved in developing Spark SQL queries, Data frames, import data from Data sources, perform transformations, perform read/write operations, save the results to output directory into HDFS.</div>
			</div>
		</li>
	</ol>
</body>
</html>